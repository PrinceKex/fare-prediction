{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from colabcode import ColabCode\n",
    "# ColabCode(port=10000, password='Nelson123')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use 1% of data to speed up initial analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/PrinceKex/fare-prediction/refs/heads/main/taxifare.csv'\n",
    "\n",
    "selected_cols = 'fare_amount,pickup_datetime,pickup_longitude,pickup_latitude,dropoff_longitude,dropoff_latitude,passenger_count'.split(',')\n",
    "\n",
    "# define the data types\n",
    "dtypes = {\n",
    "  'fare_amount': 'float32',\n",
    "  'pickup_datetime': 'float32',\n",
    "  \"pickup_longitude\": 'float32',\n",
    "  'pickup_latitude': 'float32',\n",
    "  'dropoff_longitude': 'float32',\n",
    "  'dropoff_latitude': 'float32',\n",
    "  'passenger_count': 'uint8'\n",
    "}\n",
    "\n",
    "# define skip row function to randomize selection\n",
    "def skip_row(row_idx):\n",
    "  if row_idx == 0:\n",
    "    return False\n",
    "  return random.random() > 0.01\n",
    "random.seed(42)\n",
    "  \n",
    "\n",
    "\n",
    "df = pd.read_csv(url, usecols=selected_cols, parse_dates=['pickup_datetime'], dtype=dtypes)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df, test_size=0.1, random_state=42)\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Explore the Dataset\n",
    "\n",
    "a. Basic info about the training set\n",
    "\n",
    "b. Basic info about the test set\n",
    "\n",
    "c. Exploratory data analysis and \n",
    " \n",
    "d. visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['pickup_datetime'].max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['pickup_datetime'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pickup_datetime'].max(),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pickup_datetime'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory data analylsis and Visualization\n",
    "Answer these questions about the data\n",
    "1. What is the busiest day of the week?\n",
    "2. What is the busiest time of the day?\n",
    "3. In which month are the fares the highest?\n",
    "4. Which pickup locations have the highest fares?\n",
    "5. Which drop location have the highest fares?\n",
    "6. What is the average ride distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Prepare Dataset for Training\n",
    "\n",
    "a. split the training and validation set\n",
    "\n",
    "b. fill/remove missing values\n",
    "\n",
    "c. extract inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(train_df, test_size=0.15, random_state=42)\n",
    "train_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.dropna()\n",
    "val_df = val_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns\n",
    "\n",
    "input_cols = ['pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude','passenger_count']\n",
    "target_col = 'fare_amount'\n",
    "\n",
    "train_inputs = train_df[input_cols]\n",
    "train_targets = train_df[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_inputs = val_df[input_cols]\n",
    "val_targets = val_df[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_inputs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_targets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Train hardcoded and Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanRegressor: \n",
    "  def fit(self, inputs, targets):\n",
    "    self.mean = targets.mean()\n",
    "\n",
    "  def predict(self, inputs):\n",
    "    return np.full(inputs.shape[0], self.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_model = MeanRegressor()\n",
    "mean_model.fit(train_inputs,  train_targets)\n",
    "mean_model.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = mean_model.predict(train_inputs)\n",
    "train_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = mean_model.predict(val_inputs)\n",
    "val_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "def rmse( targets, preds):\n",
    "  return root_mean_squared_error(targets, preds)\n",
    "\n",
    "train_rmse = rmse(train_targets, train_preds)\n",
    "train_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_rmse = rmse(val_targets, val_preds)\n",
    "val_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a Linear Regression Model on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(train_inputs, train_targets)\n",
    "\n",
    "train_preds = linear_model.predict(train_inputs)\n",
    "train_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rmse = rmse(train_targets, train_preds)\n",
    "train_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_rmse = rmse(val_targets, val_preds)\n",
    "val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = linear_model.predict(test_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the sample submission file and submit to kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_submit(model, test_inputs, fname):\n",
    "  test_preds = model.predict(test_inputs)\n",
    "  sub_df = pd.read_csv('sample_submission.csv')\n",
    "  sub_df['fare_amount'] = test_preds\n",
    "  sub_df.to_csv(fname, index=None)\n",
    "  return sub_df\n",
    "\n",
    "predict_and_submit(linear_model, 'linear_model_submission')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering.\n",
    "\n",
    "a. extract part of the date\n",
    "\n",
    "b. remove outliers and invalid date\n",
    "\n",
    "c. add distance between pickups and drop\n",
    "\n",
    "d. add distance from landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dateparts(df, col):\n",
    "  df[col + '_year'] = df[col].dt.year\n",
    "  df[col + '_month'] = df[col].dt.month\n",
    "  df[col + '_day'] = df[col].dt.day\n",
    "  df[col + '_weekday'] = df[col].dt.weekday\n",
    "  df[col + '_hour'] = df[col].dt.hour\n",
    "\n",
    "add_dateparts(train_df, 'pickup_datetime')\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_dateparts(val_df, 'pickup_datetime')\n",
    "val_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_dateparts(test_df, 'pickup_datetime')\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Add distance between pickups and dropoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def hoversine_np(lat1, lat2, len1, len2):\n",
    "  #calculate the distance between two points on the earth(specified as decimal degree)\n",
    "  # all args must be of equal length\n",
    "\n",
    "  len1, lat1, len2, lat2 = map(np.radians, [len1, lat1, len2, lat2])\n",
    "\n",
    "  dlen = len2 - len1\n",
    "  dlat = lat2 - lat1\n",
    "\n",
    "  a = np.sin(dlat/2)**2 * np.cos(lat1) * np.cos(lat2) * np.sin(dlen/2)**2\n",
    "\n",
    "  c = 2 * np.arcsin(np.sqrt(a))\n",
    "  km = 6367 * c\n",
    "  return km\n",
    "\n",
    "def add_trip_distance(df):\n",
    "  df['trip_distance'] = haversine_np(df['pickup_longitude'], df['pickup_latitude'], df['dropoff_longitude'], df['dropoff_latitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
